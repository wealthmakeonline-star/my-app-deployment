2026-01-06 11:02:09,114 - __main__ - INFO - üåê API Server Logging Initialized
2026-01-06 11:02:09,115 - __main__ - INFO - üìù Logs saved to: logs/dq_api_20260106_110209.log
2026-01-06 11:02:09,165 - __main__ - INFO - APP_SETTINGS loaded. Audit enabled: True
2026-01-06 11:02:09,166 - __main__ - INFO - ‚úÖ All DQ modules loaded successfully
2026-01-06 11:02:09,169 - dq_error_log - INFO - ErrorLogger initialized with database: dq_checks
2026-01-06 11:02:09,169 - dq_audit - INFO - Audit class initialized with database: dq_checks
2026-01-06 11:02:09,170 - __main__ - INFO - ‚úÖ ErrorLogger and DataQualityAudit initialized
2026-01-06 11:02:09,177 - __main__ - INFO - üöÄ Starting Data Quality Framework API
2026-01-06 11:02:09,178 - __main__ - INFO - üìä Modules available: True
2026-01-06 11:02:09,179 - __main__ - INFO - üîß Config file mode: False
2026-01-06 11:02:09,179 - __main__ - INFO - üìã Available endpoints:
2026-01-06 11:02:09,180 - __main__ - INFO -   GET  /              - API status
2026-01-06 11:02:09,182 - __main__ - INFO -   GET  /api/health    - Health check
2026-01-06 11:02:09,182 - __main__ - INFO -   POST /api/check-single - Single source analysis
2026-01-06 11:02:09,183 - __main__ - INFO -   POST /api/compare   - Source-target comparison
2026-01-06 11:02:09,184 - __main__ - INFO -   POST /api/upload    - File upload
2026-01-06 11:02:09,185 - __main__ - INFO -   GET  /api/sessions  - List sessions
2026-01-06 11:02:09,186 - __main__ - INFO -   GET  /api/sessions/<id> - Get session data
2026-01-06 11:02:09,187 - __main__ - INFO -   GET  /api/debug-db  - Database debug
2026-01-06 11:02:09,188 - __main__ - INFO - üåç Server starting on 0.0.0.0:5000 (debug=False)
2026-01-06 11:02:14,500 - __main__ - INFO - POST /api/database-hierarchy - Request started
2026-01-06 11:02:14,501 - __main__ - INFO - Getting database hierarchy for postgresql
2026-01-06 11:02:14,502 - __main__ - INFO - Database: Not provided
2026-01-06 11:02:14,503 - __main__ - INFO - Schema: Not provided
2026-01-06 11:02:14,503 - database_navigator - INFO - DatabaseNavigator initialized
2026-01-06 11:02:14,504 - __main__ - INFO - Connecting with config: {'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:02:14,505 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:02:14,506 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:02:14,507 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=postgres, user=postgres
2026-01-06 11:02:14,622 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4FC260; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:14,622 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: postgres
2026-01-06 11:02:14,623 - __main__ - INFO - Getting databases list...
2026-01-06 11:02:14,624 - database_navigator - INFO - get_databases() called. db_type: postgresql, connection exists: True
2026-01-06 11:02:14,625 - database_navigator - INFO - DEBUG: Checking connection - self.connection = <connection object at 0x00000237DD4FC260; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:14,632 - database_navigator - INFO - Raw rows: [('dq_checks',), ('finewise-testdb',), ('postgres',), ('template0',), ('template1',)]
2026-01-06 11:02:14,633 - database_navigator - INFO - Found 5 databases
2026-01-06 11:02:14,635 - __main__ - INFO - Found 5 databases
2026-01-06 11:02:14,636 - __main__ - INFO - Completed with status 200 in 0.136s
2026-01-06 11:02:22,242 - __main__ - INFO - POST /api/database-hierarchy - Request started
2026-01-06 11:02:22,243 - __main__ - INFO - Getting database hierarchy for postgresql
2026-01-06 11:02:22,244 - __main__ - INFO - Database: Not provided
2026-01-06 11:02:22,245 - __main__ - INFO - Schema: Not provided
2026-01-06 11:02:22,246 - database_navigator - INFO - DatabaseNavigator initialized
2026-01-06 11:02:22,247 - __main__ - INFO - Connecting with config: {'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:02:22,248 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:02:22,249 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:02:22,250 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=postgres, user=postgres
2026-01-06 11:02:22,356 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4B3890; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:22,358 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: postgres
2026-01-06 11:02:22,359 - __main__ - INFO - Getting databases list...
2026-01-06 11:02:22,359 - database_navigator - INFO - get_databases() called. db_type: postgresql, connection exists: True
2026-01-06 11:02:22,361 - database_navigator - INFO - DEBUG: Checking connection - self.connection = <connection object at 0x00000237DD4B3890; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:22,369 - database_navigator - INFO - Raw rows: [('dq_checks',), ('finewise-testdb',), ('postgres',), ('template0',), ('template1',)]
2026-01-06 11:02:22,370 - database_navigator - INFO - Found 5 databases
2026-01-06 11:02:22,371 - __main__ - INFO - Found 5 databases
2026-01-06 11:02:22,372 - __main__ - INFO - Completed with status 200 in 0.130s
2026-01-06 11:02:36,133 - __main__ - INFO - POST /api/database-hierarchy - Request started
2026-01-06 11:02:36,134 - __main__ - INFO - Getting database hierarchy for postgresql
2026-01-06 11:02:36,135 - __main__ - INFO - Database: Not provided
2026-01-06 11:02:36,137 - __main__ - INFO - Schema: Not provided
2026-01-06 11:02:36,138 - database_navigator - INFO - DatabaseNavigator initialized
2026-01-06 11:02:36,138 - __main__ - INFO - Connecting with config: {'host': 'localhost', 'port': 5432, 'database': 'postgres', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:02:36,139 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:02:36,140 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:02:36,141 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=postgres, user=postgres
2026-01-06 11:02:36,246 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4B3890; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:36,248 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: postgres
2026-01-06 11:02:36,249 - __main__ - INFO - Getting databases list...
2026-01-06 11:02:36,251 - database_navigator - INFO - get_databases() called. db_type: postgresql, connection exists: True
2026-01-06 11:02:36,252 - database_navigator - INFO - DEBUG: Checking connection - self.connection = <connection object at 0x00000237DD4B3890; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:02:36,261 - database_navigator - INFO - Raw rows: [('dq_checks',), ('finewise-testdb',), ('postgres',), ('template0',), ('template1',)]
2026-01-06 11:02:36,261 - database_navigator - INFO - Found 5 databases
2026-01-06 11:02:36,263 - __main__ - INFO - Found 5 databases
2026-01-06 11:02:36,265 - __main__ - INFO - Completed with status 200 in 0.132s
2026-01-06 11:04:21,708 - __main__ - INFO - POST /api/database-hierarchy - Request started
2026-01-06 11:04:21,708 - __main__ - INFO - Getting database hierarchy for postgresql
2026-01-06 11:04:21,711 - __main__ - INFO - Database: dq_checks
2026-01-06 11:04:21,712 - __main__ - INFO - Schema: Not provided
2026-01-06 11:04:21,714 - database_navigator - INFO - DatabaseNavigator initialized
2026-01-06 11:04:21,715 - __main__ - INFO - Connecting with config: {'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:04:21,716 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:04:21,716 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:04:21,717 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=postgres, user=postgres
2026-01-06 11:04:21,854 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4B3890; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:04:21,856 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: postgres
2026-01-06 11:04:21,856 - __main__ - INFO - Getting schemas for database: dq_checks
2026-01-06 11:04:21,858 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:04:21,859 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:04:21,861 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=dq_checks, user=postgres
2026-01-06 11:04:21,985 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4B39A0; dsn: 'user=postgres password=xxx dbname=dq_checks host=localhost port=5432', closed: 0>
2026-01-06 11:04:21,986 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: dq_checks
2026-01-06 11:04:22,000 - database_navigator - INFO - Found 1 schemas
2026-01-06 11:04:22,001 - __main__ - INFO - Found 1 schemas
2026-01-06 11:04:22,002 - __main__ - INFO - Completed with status 200 in 0.294s
2026-01-06 11:05:43,140 - __main__ - INFO - POST /api/database-hierarchy - Request started
2026-01-06 11:05:43,140 - __main__ - INFO - Getting database hierarchy for postgresql
2026-01-06 11:05:43,142 - __main__ - INFO - Database: dq_checks
2026-01-06 11:05:43,143 - __main__ - INFO - Schema: public
2026-01-06 11:05:43,144 - database_navigator - INFO - DatabaseNavigator initialized
2026-01-06 11:05:43,145 - __main__ - INFO - Connecting with config: {'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:05:43,146 - database_navigator - INFO - Connecting to POSTGRESQL...
2026-01-06 11:05:43,147 - database_navigator - INFO - Connecting to PostgreSQL...
2026-01-06 11:05:43,147 - database_navigator - INFO - Connecting to PostgreSQL: host=localhost, port=5432, database=postgres, user=postgres
2026-01-06 11:05:43,373 - database_navigator - INFO - Connection object created: <connection object at 0x00000237DD4B39A0; dsn: 'user=postgres password=xxx dbname=postgres host=localhost port=5432', closed: 0>
2026-01-06 11:05:43,374 - database_navigator - INFO - ‚úÖ PostgreSQL connection successful to database: postgres
2026-01-06 11:05:43,376 - __main__ - INFO - Getting tables for database: dq_checks, schema: public
2026-01-06 11:05:44,229 - database_navigator - INFO - Found 2 tables in schema 'public'
2026-01-06 11:05:44,230 - __main__ - INFO - Found 2 tables
2026-01-06 11:05:44,231 - __main__ - INFO - Completed with status 200 in 1.092s
2026-01-06 11:07:32,071 - __main__ - INFO - POST /api/test-db-connection - Request started
2026-01-06 11:07:32,196 - __main__ - INFO - Database connection test: POSTGRESQL connection successful
2026-01-06 11:07:32,198 - __main__ - INFO - Completed with status 200 in 0.128s
2026-01-06 11:07:59,093 - __main__ - INFO - POST /api/check-single - Request started
2026-01-06 11:07:59,094 - __main__ - INFO - Single source analysis request received
2026-01-06 11:07:59,095 - __main__ - INFO - Starting analysis for session SINGLE_20260106_110759_3685c414
2026-01-06 11:07:59,097 - __main__ - INFO - UI Data being passed to dq_unified:
2026-01-06 11:07:59,098 - __main__ - INFO -   source_type: database
2026-01-06 11:07:59,098 - __main__ - INFO -   db_config: {'type': 'postgresql', 'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'schema': 'public', 'table': 'employees', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:07:59,100 - __main__ - INFO -   mandatory_fields: None
2026-01-06 11:07:59,101 - dq_unified - INFO - ==================================================
2026-01-06 11:07:59,101 - dq_unified - INFO - RUN_SINGLE_SOURCE_ANALYSIS_UI - START
2026-01-06 11:07:59,101 - dq_unified - INFO - Prompting user for data source type
2026-01-06 11:07:59,103 - dq_unified - INFO - UI Data source_type: database
2026-01-06 11:07:59,104 - dq_unified - INFO - Using source_type from UI data: database
2026-01-06 11:07:59,105 - dq_unified - INFO - Loading data from DATABASE...
2026-01-06 11:07:59,106 - dq_unified - INFO - Loading data from DATABASE
2026-01-06 11:07:59,107 - dq_unified - INFO - Loading large database table: employees
2026-01-06 11:07:59,109 - dq_unified - INFO - Normalized DB config with schema: public
2026-01-06 11:07:59,220 - dq_unified - ERROR - Error loading large database: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^
Traceback (most recent call last):
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 213, in load_large_database
    return LargeDatasetHandler._load_large_postgresql(db_config, max_rows)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 252, in _load_large_postgresql
    cursor.execute(f"SELECT COUNT(*) FROM {full_table_name}")
psycopg2.errors.UndefinedTable: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^

2026-01-06 11:07:59,224 - dq_unified - ERROR - Error loading data from database: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^
Traceback (most recent call last):
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 1226, in load_data_from_source
    df = LargeDatasetHandler.load_large_database(source_config, max_rows=max_rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 213, in load_large_database
    return LargeDatasetHandler._load_large_postgresql(db_config, max_rows)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 252, in _load_large_postgresql
    cursor.execute(f"SELECT COUNT(*) FROM {full_table_name}")
psycopg2.errors.UndefinedTable: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^

2026-01-06 11:07:59,226 - dq_unified - ERROR - No data loaded or dataset is empty
2026-01-06 11:07:59,226 - __main__ - WARNING - Analysis completed with errors: No data loaded or dataset is empty
2026-01-06 11:07:59,227 - __main__ - INFO - Completed with status 200 in 0.133s
2026-01-06 11:09:03,337 - __main__ - INFO - POST /api/check-single - Request started
2026-01-06 11:09:03,338 - __main__ - INFO - Single source analysis request received
2026-01-06 11:09:03,340 - __main__ - INFO - Starting analysis for session SINGLE_20260106_110903_5419bd21
2026-01-06 11:09:03,341 - __main__ - INFO - UI Data being passed to dq_unified:
2026-01-06 11:09:03,342 - __main__ - INFO -   source_type: database
2026-01-06 11:09:03,343 - __main__ - INFO -   db_config: {'type': 'postgresql', 'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'schema': 'public', 'table': 'employees', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:09:03,344 - __main__ - INFO -   mandatory_fields: all
2026-01-06 11:09:03,345 - dq_unified - INFO - ==================================================
2026-01-06 11:09:03,345 - dq_unified - INFO - RUN_SINGLE_SOURCE_ANALYSIS_UI - START
2026-01-06 11:09:03,346 - dq_unified - INFO - Prompting user for data source type
2026-01-06 11:09:03,348 - dq_unified - INFO - UI Data source_type: database
2026-01-06 11:09:03,348 - dq_unified - INFO - Using source_type from UI data: database
2026-01-06 11:09:03,349 - dq_unified - INFO - Loading data from DATABASE...
2026-01-06 11:09:03,351 - dq_unified - INFO - Loading data from DATABASE
2026-01-06 11:09:03,351 - dq_unified - INFO - Loading large database table: employees
2026-01-06 11:09:03,352 - dq_unified - INFO - Normalized DB config with schema: public
2026-01-06 11:09:03,565 - dq_unified - ERROR - Error loading large database: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^
Traceback (most recent call last):
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 213, in load_large_database
    return LargeDatasetHandler._load_large_postgresql(db_config, max_rows)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 252, in _load_large_postgresql
    cursor.execute(f"SELECT COUNT(*) FROM {full_table_name}")
psycopg2.errors.UndefinedTable: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^

2026-01-06 11:09:03,566 - dq_unified - ERROR - Error loading data from database: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^
Traceback (most recent call last):
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 1226, in load_data_from_source
    df = LargeDatasetHandler.load_large_database(source_config, max_rows=max_rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 213, in load_large_database
    return LargeDatasetHandler._load_large_postgresql(db_config, max_rows)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\003160\OneDrive - wisseninfotech.com\Documents\DQ-Checks-Shashi\Data_Quality_Framework\dq_unified.py", line 252, in _load_large_postgresql
    cursor.execute(f"SELECT COUNT(*) FROM {full_table_name}")
psycopg2.errors.UndefinedTable: relation "public.employees" does not exist
LINE 1: SELECT COUNT(*) FROM public.employees
                             ^

2026-01-06 11:09:03,569 - dq_unified - ERROR - No data loaded or dataset is empty
2026-01-06 11:09:03,569 - __main__ - WARNING - Analysis completed with errors: No data loaded or dataset is empty
2026-01-06 11:09:03,570 - __main__ - INFO - Completed with status 200 in 0.233s
2026-01-06 11:09:59,422 - __main__ - INFO - POST /api/check-single - Request started
2026-01-06 11:09:59,423 - __main__ - INFO - Single source analysis request received
2026-01-06 11:09:59,424 - __main__ - INFO - Starting analysis for session SINGLE_20260106_110959_82454443
2026-01-06 11:09:59,425 - __main__ - INFO - UI Data being passed to dq_unified:
2026-01-06 11:09:59,427 - __main__ - INFO -   source_type: database
2026-01-06 11:09:59,428 - __main__ - INFO -   db_config: {'type': 'postgresql', 'host': 'localhost', 'port': 5432, 'database': 'dq_checks', 'schema': 'public', 'table': 'employee', 'user': 'postgres', 'password': 'postgres'}
2026-01-06 11:09:59,428 - __main__ - INFO -   mandatory_fields: all
2026-01-06 11:09:59,429 - dq_unified - INFO - ==================================================
2026-01-06 11:09:59,430 - dq_unified - INFO - RUN_SINGLE_SOURCE_ANALYSIS_UI - START
2026-01-06 11:09:59,430 - dq_unified - INFO - Prompting user for data source type
2026-01-06 11:09:59,431 - dq_unified - INFO - UI Data source_type: database
2026-01-06 11:09:59,431 - dq_unified - INFO - Using source_type from UI data: database
2026-01-06 11:09:59,432 - dq_unified - INFO - Loading data from DATABASE...
2026-01-06 11:09:59,432 - dq_unified - INFO - Loading data from DATABASE
2026-01-06 11:09:59,433 - dq_unified - INFO - Loading large database table: employee
2026-01-06 11:09:59,433 - dq_unified - INFO - Normalized DB config with schema: public
2026-01-06 11:09:59,544 - dq_unified - INFO - PostgreSQL table public.employee has 89,999 rows
2026-01-06 11:09:59,544 - dq_unified - INFO - Loading 89,999 rows from PostgreSQL...
2026-01-06 11:09:59,942 - dq_unified - INFO - Loaded 89,999 rows from PostgreSQL
2026-01-06 11:10:01,040 - dq_unified - INFO - Memory optimization: 60.9MB -> 25.8MB (Saved: 35.1MB)
2026-01-06 11:10:01,041 - dq_unified - INFO - Standardizing data types...
2026-01-06 11:10:02,635 - dq_unified - INFO - Data type standardization complete
2026-01-06 11:10:02,782 - dq_unified - INFO - Loaded 89,999 rows, 12 columns. Memory: 182.9MB total, 18.9MB for dataframe
2026-01-06 11:10:02,784 - dq_unified - INFO - Data loaded: 89,999 rows, 12 columns
2026-01-06 11:10:02,785 - dq_error_log - INFO - ErrorLogger initialized with database: dq_checks
2026-01-06 11:10:02,787 - dq_unified - INFO - Session ID: SINGLE_20260106_111002
2026-01-06 11:10:02,787 - dq_unified - INFO - ==================================================
2026-01-06 11:10:02,788 - dq_unified - INFO - Starting quality checks...
2026-01-06 11:10:02,788 - dq_unified - INFO - ==================================================
2026-01-06 11:10:02,789 - dq_unified - INFO - 1. Checking for null/empty values...
2026-01-06 11:10:02,790 - dq_unified - INFO - Checking for null/empty values
2026-01-06 11:10:02,792 - dq_unified - INFO - DataFrame shape: (89999, 12)
2026-01-06 11:10:02,792 - dq_unified - INFO - Columns: ['id', 'customer_id', 'transaction_id', 'customer_name', 'email', 'phone', 'transaction_date', 'amount', 'quantity', 'age', 'status', 'description']
2026-01-06 11:10:02,793 - dq_unified - INFO - Data source: Database: postgresql - Table: employee
2026-01-06 11:10:02,795 - dq_unified - INFO - DataFrame dtypes: {'id': dtype('int64'), 'customer_id': dtype('O'), 'transaction_id': dtype('O'), 'customer_name': CategoricalDtype(categories=['                     Michael Smith', '      Susan Miller',
                  'David Brown', 'David Brown  ', 'David Davis',
                  'David Davis  ', 'David Johnson', 'David Johnson  ',
                  'David Jones', 'David Jones  ',
                  ...
                  'William Johnson', 'William Johnson  ', 'William Jones',
                  'William Jones  ', 'William Miller', 'William Miller  ',
                  'William Smith', 'William Smith  ', 'William Williams',
                  'William Williams  '],
, ordered=False, categories_dtype=object), 'email': CategoricalDtype(categories=['                             robert.johnson@outlook.com',
                  'NaN', 'david.brown.company.com', 'david.brown@company.com',
                  'david.brown@gmail.com', 'david.brown@hotmail.com',
                  'david.brown@invalid', 'david.brown@outlook.com',
                  'david.brown@yahoo.com', 'david.davis.company.com',
                  ...
                  'william.smith@invalid', 'william.smith@outlook.com',
                  'william.smith@yahoo.com', 'william.williams.company.com',
                  'william.williams@company.com', 'william.williams@gmail.com',
                  'william.williams@hotmail.com', 'william.williams@invalid',
                  'william.williams@outlook.com',
                  'william.williams@yahoo.com'],
, ordered=False, categories_dtype=object), 'phone': dtype('O'), 'transaction_date': CategoricalDtype(categories=['01-01-2023', '01-01-2024', '01-02-2023', '01-03-2023',
                  '01-04-2023', '01-05-2023', '01-06-2023', '01-07-2023',
                  '01-08-2023', '01-09-2023',
                  ...
                  '30-10-2023', '30-11-2023', '30-12-2023', '31-01-2023',
                  '31-03-2023', '31-05-2023', '31-07-2023', '31-08-2023',
                  '31-10-2023', '31-12-2023'],
, ordered=False, categories_dtype=object), 'amount': dtype('float64'), 'quantity': dtype('int64'), 'age': dtype('int64'), 'status': CategoricalDtype(categories=['ACTIVE', 'CANCELLED', 'COMPLETED', 'INACTIVE', 'PENDING'], ordered=False, categories_dtype=object), 'description': CategoricalDtype(categories=['  Text with leading spaces', 'Normal text without issues',
                  'Text with\ttabs', 'Text with\nnewlines',
                  'Text with  multiple   spaces', 'Text with - dashes',
                  'Text with mixed CAPITAL and lowercase',
                  'Text with trailing spaces  ', 'Text with! exclamations',
                  'Text with"quotes"', 'Text with#hashtags',
                  'Text with$dollar signs',
                  'Text with$dollar signs                       ',
                  'Text with%percent signs', 'Text with& ampersands',
                  'Text with'apostrophes', 'Text with(parentheses)',
                  'Text with*asterisks', 'Text with, commas',
                  'Text with. periods', 'Text with/slashes',
                  'Text with; semicolons', 'Text with<angle brackets>',
                  'Text with? questions', 'Text with@at signs',
                  'Text with[brackets]', 'Text with\backslashes',
                  'Text with_underscores', 'Text with`backticks',
                  'Text with{braces}', 'Text with|pipes', 'Text with~tildes'],
, ordered=False, categories_dtype=object)}
2026-01-06 11:10:02,796 - dq_unified - INFO - First 2 rows (first 3 columns only):
2026-01-06 11:10:02,800 - dq_unified - INFO -   Row 0: {'id': 'np.int64(78303)', 'customer_id': "'CUST078303'", 'transaction_id': "'TX00078303'"}
2026-01-06 11:10:02,802 - dq_unified - INFO -   Row 1: {'id': 'np.int64(66465)', 'customer_id': "'CUST066465'", 'transaction_id': "'TX00066465'"}
2026-01-06 11:10:03,745 - dq_unified - INFO - Column 'id': No missing cells
2026-01-06 11:10:04,634 - dq_unified - INFO - Column 'customer_id': No missing cells
2026-01-06 11:10:05,514 - dq_unified - INFO - Column 'transaction_id': No missing cells
2026-01-06 11:10:06,682 - dq_unified - INFO -   Missing samples: ["'NaN'", "'NaN'", "'NaN'"]
2026-01-06 11:10:06,684 - dq_unified - INFO -   Not missing samples: ["'Michael Davis'", "'Susan Brown'", "'Sarah Davis'"]
2026-01-06 11:10:06,685 - dq_unified - WARNING - Column 'customer_name': 3,510 missing cells (3.9%)
2026-01-06 11:10:06,688 - dq_unified - WARNING - Column 'customer_name': 3,510 missing cells (3.9%)
2026-01-06 11:10:46,822 - dq_error_log - INFO - Starting batch logging for 3510 errors, session: SINGLE_20260106_111002
2026-01-06 11:10:47,057 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:10:47,184 - dq_error_log - INFO - Batch 2: Successfully logged 500 errors
2026-01-06 11:10:47,256 - dq_error_log - INFO - Batch 3: Successfully logged 500 errors
2026-01-06 11:10:47,334 - dq_error_log - INFO - Batch 4: Successfully logged 500 errors
2026-01-06 11:10:47,410 - dq_error_log - INFO - Batch 5: Successfully logged 500 errors
2026-01-06 11:10:47,486 - dq_error_log - INFO - Batch 6: Successfully logged 500 errors
2026-01-06 11:10:47,563 - dq_error_log - INFO - Batch 7: Successfully logged 500 errors
2026-01-06 11:10:47,574 - dq_error_log - INFO - Batch 8: Successfully logged 10 errors
2026-01-06 11:10:47,575 - dq_error_log - INFO - Progress: 3510/3510 errors processed
2026-01-06 11:10:47,576 - dq_error_log - INFO - COMPLETE: Logged 3510/3510 errors for session SINGLE_20260106_111002
2026-01-06 11:10:48,066 - dq_unified - INFO -   Missing samples: ["'NaN'", "'NaN'", "'NaN'"]
2026-01-06 11:10:48,067 - dq_unified - INFO -   Not missing samples: ["'david.jones@company.com'", "'jennifer.williams@gmail.com'", "'james.davis@hotmail.com'"]
2026-01-06 11:10:48,067 - dq_unified - WARNING - Column 'email': 1,516 missing cells (1.7%)
2026-01-06 11:10:48,068 - dq_unified - WARNING - Column 'email': 1,516 missing cells (1.7%)
2026-01-06 11:11:00,041 - dq_error_log - INFO - Starting batch logging for 1516 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:00,138 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:11:00,232 - dq_error_log - INFO - Batch 2: Successfully logged 500 errors
2026-01-06 11:11:00,328 - dq_error_log - INFO - Batch 3: Successfully logged 500 errors
2026-01-06 11:11:00,342 - dq_error_log - INFO - Batch 4: Successfully logged 16 errors
2026-01-06 11:11:00,343 - dq_error_log - INFO - Progress: 1516/1516 errors processed
2026-01-06 11:11:00,343 - dq_error_log - INFO - COMPLETE: Logged 1516/1516 errors for session SINGLE_20260106_111002
2026-01-06 11:11:00,848 - dq_unified - INFO -   Missing samples: ["'NaN'", "'NaN'", "'NaN'"]
2026-01-06 11:11:00,849 - dq_unified - INFO -   Not missing samples: ["'212-127-8383'", "'(212) 706-7216'", "'12123928735'"]
2026-01-06 11:11:00,850 - dq_unified - WARNING - Column 'phone': 1,280 missing cells (1.4%)
2026-01-06 11:11:00,851 - dq_unified - WARNING - Column 'phone': 1,280 missing cells (1.4%)
2026-01-06 11:11:07,484 - dq_error_log - INFO - Starting batch logging for 1280 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:07,570 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:11:07,653 - dq_error_log - INFO - Batch 2: Successfully logged 500 errors
2026-01-06 11:11:07,706 - dq_error_log - INFO - Batch 3: Successfully logged 280 errors
2026-01-06 11:11:07,707 - dq_error_log - INFO - Progress: 1280/1280 errors processed
2026-01-06 11:11:07,708 - dq_error_log - INFO - COMPLETE: Logged 1280/1280 errors for session SINGLE_20260106_111002
2026-01-06 11:11:08,077 - dq_unified - INFO - Column 'transaction_date': No missing cells
2026-01-06 11:11:08,550 - dq_unified - INFO -   Missing samples: ['nan', 'nan', 'nan']
2026-01-06 11:11:08,551 - dq_unified - INFO -   Not missing samples: ['8653.56', '1948.44', '237.49']
2026-01-06 11:11:08,551 - dq_unified - WARNING - Column 'amount': 1,133 missing cells (1.3%)
2026-01-06 11:11:08,552 - dq_unified - WARNING - Column 'amount': 1,133 missing cells (1.3%)
2026-01-06 11:11:14,688 - dq_error_log - INFO - Starting batch logging for 1133 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:14,777 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:11:14,864 - dq_error_log - INFO - Batch 2: Successfully logged 500 errors
2026-01-06 11:11:14,880 - dq_error_log - INFO - Batch 3: Successfully logged 133 errors
2026-01-06 11:11:14,882 - dq_error_log - INFO - Progress: 1133/1133 errors processed
2026-01-06 11:11:14,883 - dq_error_log - INFO - COMPLETE: Logged 1133/1133 errors for session SINGLE_20260106_111002
2026-01-06 11:11:15,328 - dq_unified - INFO - Column 'quantity': No missing cells
2026-01-06 11:11:15,688 - dq_unified - INFO - Column 'age': No missing cells
2026-01-06 11:11:16,137 - dq_unified - INFO - Column 'status': No missing cells
2026-01-06 11:11:16,581 - dq_unified - INFO - Column 'description': No missing cells
2026-01-06 11:11:16,581 - dq_unified - INFO - Total missing cells found: 7,439
2026-01-06 11:11:16,582 - dq_unified - INFO - === Analyzing PostgreSQL database ===
2026-01-06 11:11:16,583 - dq_unified - INFO - First column 'id' samples: ['78303', '66465', '93228']
2026-01-06 11:11:16,584 - dq_unified - INFO - ============================================================
2026-01-06 11:11:16,585 - dq_unified - INFO - MISSING VALUE SUMMARY
2026-01-06 11:11:16,585 - dq_unified - INFO - ============================================================
2026-01-06 11:11:16,586 - dq_unified - INFO - customer_name: 3,510 missing (3.9%)
2026-01-06 11:11:16,587 - dq_unified - INFO - email: 1,516 missing (1.7%)
2026-01-06 11:11:16,587 - dq_unified - INFO - phone: 1,280 missing (1.4%)
2026-01-06 11:11:16,588 - dq_unified - INFO - amount: 1,133 missing (1.3%)
2026-01-06 11:11:16,589 - dq_unified - INFO - ============================================================
2026-01-06 11:11:16,590 - dq_unified - INFO -    Found 7,439 empty cells
2026-01-06 11:11:16,590 - dq_unified - INFO - 2. Checking for duplicate rows...
2026-01-06 11:11:16,591 - dq_unified - INFO - Checking for duplicate rows
2026-01-06 11:11:16,592 - dq_unified - INFO - Cleaning data (removing whitespace)...
2026-01-06 11:11:16,602 - dq_unified - INFO - Columns after cleaning: ['id', 'customer_id', 'transaction_id', 'customer_name', 'email', 'phone', 'transaction_date', 'amount', 'quantity', 'age', 'status', 'description']
2026-01-06 11:11:26,798 - dq_unified - INFO - Sample of first column after cleaning: '78303'
2026-01-06 11:11:26,798 - dq_unified - INFO - Sample of row 6 first column: '19261'
2026-01-06 11:11:26,799 - dq_unified - INFO - Total rows to check: 89999
2026-01-06 11:11:26,801 - dq_unified - INFO - Checking first column 'id' for serial numbers
2026-01-06 11:11:26,802 - dq_unified - INFO - First 5 values: ['78303', '66465', '93228', '1748', '80005']
2026-01-06 11:11:26,803 - dq_unified - INFO -   Row 1: '78303' ‚Üí 78303.0 (numeric)
2026-01-06 11:11:26,804 - dq_unified - INFO -   Row 2: '66465' ‚Üí 66465.0 (numeric)
2026-01-06 11:11:26,805 - dq_unified - INFO -   Row 3: '93228' ‚Üí 93228.0 (numeric)
2026-01-06 11:11:26,805 - dq_unified - INFO - First column values not sequential: [78303.0, 66465.0, 93228.0]
2026-01-06 11:11:26,806 - dq_unified - INFO - Checking duplicates on ALL columns
2026-01-06 11:11:26,806 - dq_unified - INFO - First few rows for comparison:
2026-01-06 11:11:26,808 - dq_unified - INFO -   Row 0: {'id': '78303', 'customer_id': 'CUST078303', 'transaction_id': 'TX00078303'}
2026-01-06 11:11:26,808 - dq_unified - INFO -   Row 1: {'id': '66465', 'customer_id': 'CUST066465', 'transaction_id': 'TX00066465'}
2026-01-06 11:11:26,809 - dq_unified - INFO -   Row 2: {'id': '93228', 'customer_id': 'CUST093228', 'transaction_id': 'TX00093228'}
2026-01-06 11:11:26,954 - dq_unified - INFO - Duplicate mask found 406 rows
2026-01-06 11:11:26,955 - dq_unified - INFO - Found 406 potential duplicate rows
2026-01-06 11:11:26,992 - dq_unified - INFO - Unique duplicate groups: 203
2026-01-06 11:11:26,993 - dq_unified - INFO - Duplicate groups found:
2026-01-06 11:11:26,994 - dq_unified - INFO -   Group sample: Pandas(Index=167, id='42732', customer_id='CUST042732', transaction_id='TX00042732', customer_name='William Davis', email='james.miller@gmail.com', phone='12127948623', transaction_date='20-01-2023', amount='7954.53', quantity='60', age='64', status='PENDING', description='Text with trailing spaces')
2026-01-06 11:11:26,995 - dq_unified - INFO -   Group sample: Pandas(Index=381, id='34440', customer_id='CUST034440', transaction_id='TX00034440', customer_name='William Miller', email='NaN', phone='NaN', transaction_date='05-09-2023', amount='1954.43', quantity='64', age='75', status='CANCELLED', description='Text with. periods')
2026-01-06 11:11:26,996 - dq_unified - INFO -   Group sample: Pandas(Index=637, id='58427', customer_id='CUST058427', transaction_id='TX00058427', customer_name='Richard Brown', email='jennifer.johnson@gmail.com', phone='2124608202', transaction_date='29-09-2023', amount='9156.7', quantity='69', age='45', status='PENDING', description='Text with multiple spaces')
2026-01-06 11:11:26,997 - dq_unified - INFO - Processing 406 duplicate indices
2026-01-06 11:11:27,014 - dq_unified - INFO - FINAL RESULT: Found 406 duplicate groups
2026-01-06 11:11:27,015 - dq_error_log - INFO - Starting batch logging for 406 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:27,085 - dq_error_log - INFO - Batch 1: Successfully logged 406 errors
2026-01-06 11:11:27,086 - dq_error_log - INFO - Progress: 406/406 errors processed
2026-01-06 11:11:27,087 - dq_error_log - INFO - COMPLETE: Logged 406/406 errors for session SINGLE_20260106_111002
2026-01-06 11:11:27,102 - dq_unified - INFO -    Found 406 duplicate rows
2026-01-06 11:11:27,102 - dq_unified - INFO - 3. Checking data formats...
2026-01-06 11:11:27,103 - dq_unified - INFO - Checking data formats
2026-01-06 11:11:27,116 - dq_unified - INFO - Detected id as numeric type
2026-01-06 11:11:27,381 - dq_unified - INFO - Detected email as email type
2026-01-06 11:11:27,384 - dq_unified - WARNING -   Row 38: 'lisa.miller_outlook.com...' doesn't match Valid email format (user@domain.com)
2026-01-06 11:11:27,387 - dq_unified - WARNING -   Row 223: 'richard.miller.company.com...' doesn't match Valid email format (user@domain.com)
2026-01-06 11:11:27,389 - dq_unified - WARNING -   Row 311: 'james.miller@invalid...' doesn't match Valid email format (user@domain.com)
2026-01-06 11:11:27,390 - dq_unified - WARNING -   Row 355: 'richard.williams@invalid...' doesn't match Valid email format (user@domain.com)
2026-01-06 11:11:27,391 - dq_unified - WARNING -   Row 416: 'susan.brown.company.com...' doesn't match Valid email format (user@domain.com)
2026-01-06 11:11:28,151 - dq_unified - INFO - Detected phone as phone type
2026-01-06 11:11:28,930 - dq_unified - INFO - Detected transaction_date as date type
2026-01-06 11:11:32,092 - dq_unified - INFO -   Date format check for transaction_date: Consistent=False, Format=['MM/DD/YYYY', 'DD-MM-YYYY or MM-DD-YYYY']
2026-01-06 11:11:32,092 - dq_unified - WARNING -   transaction_date: Inconsistent date formats: ['MM/DD/YYYY', 'DD-MM-YYYY or MM-DD-YYYY']
2026-01-06 11:11:34,916 - dq_unified - INFO - Detected amount as numeric type
2026-01-06 11:11:35,099 - dq_unified - INFO - Detected quantity as numeric type
2026-01-06 11:11:35,263 - dq_unified - INFO - Detected age as numeric type
2026-01-06 11:11:38,859 - dq_unified - INFO - Total format issues found: 727
2026-01-06 11:11:38,861 - dq_error_log - INFO - Starting batch logging for 727 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:38,958 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:11:39,000 - dq_error_log - INFO - Batch 2: Successfully logged 227 errors
2026-01-06 11:11:39,001 - dq_error_log - INFO - Progress: 727/727 errors processed
2026-01-06 11:11:39,002 - dq_error_log - INFO - COMPLETE: Logged 727/727 errors for session SINGLE_20260106_111002
2026-01-06 11:11:39,003 - dq_unified - INFO -    Found 727 format issues
2026-01-06 11:11:39,003 - dq_unified - INFO - 4. Checking mandatory fields...
2026-01-06 11:11:39,004 - dq_unified - INFO - Checking mandatory fields
2026-01-06 11:11:39,004 - dq_unified - INFO - Available columns: ['id', 'customer_id', 'transaction_id', 'customer_name', 'email', 'phone', 'transaction_date', 'amount', 'quantity', 'age', 'status', 'description']
2026-01-06 11:11:39,005 - dq_unified - INFO - Checking ALL columns as mandatory: ['id', 'customer_id', 'transaction_id', 'customer_name', 'email', 'phone', 'transaction_date', 'amount', 'quantity', 'age', 'status', 'description']
2026-01-06 11:11:39,326 - dq_unified - INFO - Mandatory field 'id': 100.0% filled
2026-01-06 11:11:39,759 - dq_unified - INFO - Mandatory field 'customer_id': 100.0% filled
2026-01-06 11:11:40,193 - dq_unified - INFO - Mandatory field 'transaction_id': 100.0% filled
2026-01-06 11:11:40,513 - dq_unified - WARNING - Mandatory field 'customer_name': 3,510 missing values (96.1% filled)
2026-01-06 11:11:40,907 - dq_unified - WARNING - Mandatory field 'email': 1,516 missing values (98.3% filled)
2026-01-06 11:11:41,390 - dq_unified - WARNING - Mandatory field 'phone': 1,280 missing values (98.6% filled)
2026-01-06 11:11:41,716 - dq_unified - INFO - Mandatory field 'transaction_date': 100.0% filled
2026-01-06 11:11:42,113 - dq_unified - WARNING - Mandatory field 'amount': 1,133 missing values (98.7% filled)
2026-01-06 11:11:42,470 - dq_unified - INFO - Mandatory field 'quantity': 100.0% filled
2026-01-06 11:11:42,796 - dq_unified - INFO - Mandatory field 'age': 100.0% filled
2026-01-06 11:11:43,157 - dq_unified - INFO - Mandatory field 'status': 100.0% filled
2026-01-06 11:11:43,500 - dq_unified - INFO - Mandatory field 'description': 100.0% filled
2026-01-06 11:11:48,370 - dq_error_log - INFO - Starting batch logging for 7439 errors, session: SINGLE_20260106_111002
2026-01-06 11:11:48,469 - dq_error_log - INFO - Batch 1: Successfully logged 500 errors
2026-01-06 11:11:48,564 - dq_error_log - INFO - Batch 2: Successfully logged 500 errors
2026-01-06 11:11:48,655 - dq_error_log - INFO - Batch 3: Successfully logged 500 errors
2026-01-06 11:11:48,787 - dq_error_log - INFO - Batch 4: Successfully logged 500 errors
2026-01-06 11:11:48,874 - dq_error_log - INFO - Batch 5: Successfully logged 500 errors
2026-01-06 11:11:48,956 - dq_error_log - INFO - Batch 6: Successfully logged 500 errors
2026-01-06 11:11:49,039 - dq_error_log - INFO - Batch 7: Successfully logged 500 errors
2026-01-06 11:11:49,119 - dq_error_log - INFO - Batch 8: Successfully logged 500 errors
2026-01-06 11:11:49,204 - dq_error_log - INFO - Batch 9: Successfully logged 500 errors
2026-01-06 11:11:49,289 - dq_error_log - INFO - Batch 10: Successfully logged 500 errors
2026-01-06 11:11:49,289 - dq_error_log - INFO - Progress: 5000/7439 errors processed
2026-01-06 11:11:49,372 - dq_error_log - INFO - Batch 11: Successfully logged 500 errors
2026-01-06 11:11:49,456 - dq_error_log - INFO - Batch 12: Successfully logged 500 errors
2026-01-06 11:11:49,543 - dq_error_log - INFO - Batch 13: Successfully logged 500 errors
2026-01-06 11:11:49,626 - dq_error_log - INFO - Batch 14: Successfully logged 500 errors
2026-01-06 11:11:49,704 - dq_error_log - INFO - Batch 15: Successfully logged 439 errors
2026-01-06 11:11:49,704 - dq_error_log - INFO - Progress: 7439/7439 errors processed
2026-01-06 11:11:49,705 - dq_error_log - INFO - COMPLETE: Logged 7439/7439 errors for session SINGLE_20260106_111002
2026-01-06 11:11:49,706 - dq_unified - INFO - All columns mandatory: 6012 unique rows with missing values
2026-01-06 11:11:49,708 - dq_unified - INFO -    Found 6,012 missing mandatory values
2026-01-06 11:11:49,708 - dq_unified - INFO - 5. Calculating quality score...
2026-01-06 11:11:49,708 - dq_unified - INFO - Calculating quality score
2026-01-06 11:11:49,711 - dq_unified - INFO - Quality Score Calculation:
2026-01-06 11:11:49,712 - dq_unified - INFO -   Total rows: 89,999
2026-01-06 11:11:49,712 - dq_unified - INFO -   Bad Rows: 6,784
2026-01-06 11:11:49,713 - dq_unified - INFO -   Good rows (no issues): 83,215
2026-01-06 11:11:49,714 - dq_unified - INFO -   Quality Score: 92.46%
2026-01-06 11:11:49,858 - dq_error_log - INFO - Retrieved 200 error logs for session SINGLE_20260106_111002
2026-01-06 11:11:49,961 - dq_error_log - INFO - Retrieved summary: 16011 total errors for session SINGLE_20260106_111002
2026-01-06 11:11:49,962 - dq_unified - INFO - Added 200 error logs to results
2026-01-06 11:11:49,963 - dq_audit - INFO - Audit class initialized with database: dq_checks
2026-01-06 11:11:49,963 - dq_audit - INFO - Starting database insertion for single_source...
2026-01-06 11:11:49,981 - dq_audit - INFO - Inserted single_source record with ID: 523
2026-01-06 11:11:50,009 - dq_audit - INFO - Retrieved 1 audit logs for session SINGLE_20260106_111002
2026-01-06 11:11:50,010 - dq_unified - INFO - Added 1 audit logs to results
2026-01-06 11:11:50,011 - dq_unified - INFO - Analysis completed successfully for Database: postgresql - Table: employee
2026-01-06 11:11:50,012 - dq_unified - INFO - Final quality score: 92.46%
2026-01-06 11:11:50,144 - dq_error_log - INFO - Retrieved 200 error logs for session SINGLE_20260106_111002
2026-01-06 11:11:50,237 - dq_error_log - INFO - Retrieved summary: 16011 total errors for session SINGLE_20260106_111002
2026-01-06 11:11:50,249 - dq_audit - INFO - Retrieved 1 audit logs for session SINGLE_20260106_111002
2026-01-06 11:11:50,250 - __main__ - INFO - Analysis completed for session SINGLE_20260106_111002
2026-01-06 11:11:50,337 - __main__ - INFO - Completed with status 200 in 110.915s
